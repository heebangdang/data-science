{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hn50Wg6t7pBJ"
   },
   "source": [
    "## Data Science - Applications\n",
    "\n",
    "In the field of Data Science, it is necessary to find the best model fit for prediction. In term of Regression, we would like to find the best model to predict continuous variable. Until now, we learnt how to select the best model by finding the highest R^2 score using Linear Regression with various predictors and interaction terms. Instead, we can apply some other algorithms that best fit for the particular problems. \n",
    "\n",
    "This section attempts to show some related Regression classifiers such as:\n",
    "- Lasso Regression\n",
    "- Ridge Regression\n",
    "- ElasticNet\n",
    "- Random Forest Regressor\n",
    "- Support Vector Regressor\n",
    "\n",
    "For the experiment, this section used Diabetes Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2028,
     "status": "ok",
     "timestamp": 1607008820555,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "U9LPeZYx7pBK"
   },
   "outputs": [],
   "source": [
    "#import \n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV9dmkzR7pBK"
   },
   "source": [
    "Loading Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 727,
     "status": "ok",
     "timestamp": 1607008822892,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "JPj-nnWS7pBK"
   },
   "outputs": [],
   "source": [
    "# Load the Diabetes dataset\n",
    "columns = \"age sex bmi map tc ldl hdl tch ltg glu\".split() # Declare the columns names\n",
    "diabetes = datasets.load_diabetes() # Call the diabetes dataset from sklearn\n",
    "df = pd.DataFrame(diabetes.data, columns=columns) # load the dataset as a pandas data frame # df = X(random variable)\n",
    "y = diabetes.target # define the target variable (dependent variable) as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1607008824170,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "pA-1ilHm7pBK",
    "outputId": "332ef648-2cd3-4fb3-e508-914fdf820464"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>map</th>\n",
       "      <th>tc</th>\n",
       "      <th>ldl</th>\n",
       "      <th>hdl</th>\n",
       "      <th>tch</th>\n",
       "      <th>ltg</th>\n",
       "      <th>glu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi       map        tc       ldl       hdl  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "        tch       ltg       glu  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# this data has been normalized\n",
    "# range : -1 ~ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPjB_4ZX7pBM"
   },
   "source": [
    "Now we can use the train_test_split function in order to make the split. The test_size=0.2 inside the function indicates the percentage of the data that should be held over for testing. It’s usually around 80/20 or 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1607008827086,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "Nj93FChG7pBM",
    "outputId": "a72621ae-ffd6-482a-8d2c-6e5a977c3fae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 10) (353,)\n",
      "(89, 10) (89,)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "#(353, 10) (353,) : training\n",
    "#(89, 10) (89,) : testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng4eAIW97pBM"
   },
   "source": [
    "Let's fit on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 786,
     "status": "ok",
     "timestamp": 1607008831311,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "0Oik9esP7pBM"
   },
   "outputs": [],
   "source": [
    "# fit a model\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBHJ0PUU7pBM"
   },
   "source": [
    "The result of the first 5 predictions are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1607008834464,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "3dM4dR4N7pBM",
    "outputId": "909283cf-4283-4b05-b337-965263ec1424"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([166.2160369 ,  68.4771832 , 276.94662252, 186.06352781,\n",
       "        81.16345835])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:5] # the first 5 testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 970,
     "status": "ok",
     "timestamp": 1607008836136,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "Aq-nbp-q7pBM",
    "outputId": "fdcc289e-7a05-425d-c924-ffd6ec8aac92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 of Linear Regression on training set: 0.55\n",
      "The R^2 of Linear Regression on test set: 0.39\n"
     ]
    }
   ],
   "source": [
    "print('The R^2 of Linear Regression on training set: {:.2f}'\n",
    "     .format(model.score(X_train, y_train)))\n",
    "print('The R^2 of Linear Regression on test set: {:.2f}'\n",
    "     .format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE46QvcU7pBN"
   },
   "source": [
    "### Ridge Regression\n",
    "\n",
    "Ridge regression is basically a regularized linear regression model. The λ parameter(has been set to 'default') is a scalar that should be learned as well, using a method called cross validation. This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1147,
     "status": "ok",
     "timestamp": 1607008838310,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "g_Ei0B4F7pBN",
    "outputId": "2096b86b-af35-49c8-e210-6278478f92fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 of Ridge classifier on training set: 0.45\n",
      "The R^2 of Ridge classifier on test set: 0.38\n"
     ]
    }
   ],
   "source": [
    "###Model Ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "model_ridge = Ridge()\n",
    "model_ridge.fit(X_train, y_train)\n",
    "print('The R^2 of Ridge classifier on training set: {:.2f}'\n",
    "     .format(model_ridge.score(X_train, y_train)))\n",
    "print('The R^2 of Ridge classifier on test set: {:.2f}'\n",
    "     .format(model_ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BTnoGCL7pBN"
   },
   "source": [
    "### Lasso (Least Absolute Shrinkage Selector Operator) Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "239dW9QD7pBN"
   },
   "source": [
    "Lasso regression analysis is a shrinkage and variable selection method for linear regression models. The goal of lasso regression is to obtain the subset of predictors that minimizes prediction error for a quantitative response variable. The lasso does this by imposing a constraint on the model parameters that causes regression coefficients for some variables to shrink toward zero. Variables with a regression coefficient equal to zero after the shrinkage process are excluded from the model. Variables with non-zero regression coefficients variables are most strongly associated with the response variable. Therefore, when you conduct a regression model it can be helpful to do a lasso regression in order to predict how many variables your model should contain. This secures that your model is not overly complex and prevents the model from over-fitting which can result in a biased and inefficient model.\n",
    "\n",
    "The only difference lasso regressison contains from ridge regression is that the regularization term is in absolute value. But this difference has a huge impact on the trade-off. Lasso method overcomes the disadvantage of Ridge regression by not only punishing high values of the coefficients β but actually setting them to zero if they are not relevant. Therefore, you might end up with fewer features included in the model than you started with, which is a huge advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1607008840302,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "qUWb4g827pBN",
    "outputId": "20019890-9b18-49a6-d886-30303b25ee0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 of Lasso classifier on training set: 0.55\n",
      "The R^2 of Lasso classifier on test set: 0.38\n"
     ]
    }
   ],
   "source": [
    "###Model Lasso regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "model_lasso = LassoCV()\n",
    "model_lasso.fit(X_train, y_train)\n",
    "print('The R^2 of Lasso classifier on training set: {:.2f}'\n",
    "     .format(model_lasso.score(X_train, y_train)))\n",
    "print('The R^2 of Lasso classifier on test set: {:.2f}'\n",
    "     .format(model_lasso.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYrRHNoD7pBN"
   },
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppEOcHed7pBN"
   },
   "source": [
    "Elastic net is basically a combination of both L1 and L2 regularization. So if you know elastic net, you can implement both Ridge and Lasso by tuning the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### L1 :Manhattan / L2 : Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1607008841293,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "1J0WOQ6X7pBN",
    "outputId": "65d903b8-a415-4d17-a781-a05d95dfd87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 of ElasticNet classifier on training set: 0.01\n",
      "The R^2 of ElasticNet classifier on test set: 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model_eln = ElasticNet()\n",
    "model_eln.fit(X_train, y_train)\n",
    "print('The R^2 of ElasticNet classifier on training set: {:.2f}'\n",
    "     .format(model_eln.score(X_train, y_train)))\n",
    "print('The R^2 of ElasticNet classifier on test set: {:.2f}'\n",
    "     .format(model_eln.score(X_test, y_test)))\n",
    "# you can not get any model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRgvbBJA7pBN"
   },
   "source": [
    "Without parameter tuning, the result of Elastic Net is not promising. Hence, you can set some parameters required on the Elastic Net to fit with your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1607008842310,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "xtw6OewS7pBN",
    "outputId": "d6464957-85bf-47f1-f530-16eea9f410ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 of ElasticNet classifier on training set: 0.54\n",
      "The R^2 of ElasticNet classifier on test set: 0.40\n"
     ]
    }
   ],
   "source": [
    "model_eln = ElasticNet(alpha=0.001, l1_ratio=0.5, normalize=False) # l1 : Manhattan distance # alpha(parameter) : can change\n",
    "model_eln.fit(X_train, y_train)\n",
    "print('The R^2 of ElasticNet classifier on training set: {:.2f}'\n",
    "     .format(model_eln.score(X_train, y_train)))\n",
    "print('The R^2 of ElasticNet classifier on test set: {:.2f}'\n",
    "     .format(model_eln.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9G4bV4po7pBN"
   },
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dh1u_bRw7pBN"
   },
   "source": [
    "A Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees.\n",
    "Approach :\n",
    "\n",
    "- Pick at random K data points from the training set.\n",
    "- Build the decision tree associated with those K data points.\n",
    "- Choose the number Ntree of trees you want to build and repeat step 1 & 2.\n",
    "- For a new data point, make each one of your Ntree trees predict the value of Y for the data point, and assign the new data point the average across all of the predicted Y values.\n",
    "\n",
    "https://www.geeksforgeeks.org/random-forest-regression-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 982,
     "status": "ok",
     "timestamp": 1607008844299,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "6HdTYaok7pBN",
    "outputId": "f85aacd9-03c0-498b-c992-130a1a7936be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 of RFR classifier on training set: 0.93\n",
      "The R^2 of RFR classifier on test set: 0.35\n"
     ]
    }
   ],
   "source": [
    "###Model Random Forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_RFR = RandomForestRegressor()\n",
    "model_RFR.fit(X_train, y_train)\n",
    "print('The R^2 of RFR classifier on training set: {:.2f}'\n",
    "     .format(model_RFR.score(X_train, y_train)))\n",
    "print('The R^2 of RFR classifier on test set: {:.2f}'\n",
    "     .format(model_RFR.score(X_test, y_test)))\n",
    "# training set >>>>>>> testing set : overfitting (model is very good for training data)\n",
    "# big accuracy difference in trainig and testing : overfitting\n",
    "# smallest gap in training and testing : good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrE4J3VV7pBN"
   },
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVn1H8jK7pBN"
   },
   "source": [
    "Support Vector Regression (SVR) is a regression algorithm, and it applies a similar technique of Support Vector Machines (SVM) for regression analysis. As we know, regression data contains continuous real numbers. To fit such type of data, the SVR model approximates the best values with a given margin called ε-tube (epsilon-tube, ε identifies a tube width) with considering the model complexity and error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1607008845227,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "TapkYQdq7pBN",
    "outputId": "7d109caa-3f8b-4b62-f6c8-2add4d005d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 of SVM classifier on training set: 0.19\n",
      "The R^2 of SVM classifier on test set: 0.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm = SVR()\n",
    "svm.fit(X_train, y_train)\n",
    "print('The R^2 of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('The R^2 of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))\n",
    "# result is not that good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBNfmZva7pBN"
   },
   "source": [
    "While using SVR, it requires to set a particular parameters to get a better result. Understanding the parameters in SVM (in this case SVR), it is necessary to understand the theoretical basis of the algorithms as well as the distribution of the dataset. For further info, please refer to the following link. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1607008846261,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "uR8Jau9n7pBN",
    "outputId": "27f091c3-c412-47c6-a390-f0173ede5246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 of SVM classifier on training set: 0.54\n",
      "The R^2 of SVM classifier on test set: 0.36\n"
     ]
    }
   ],
   "source": [
    "# changing parameter again\n",
    "from sklearn.svm import SVR\n",
    "svm = SVR(kernel='linear', C=100000, gamma='auto')\n",
    "svm.fit(X_train, y_train)\n",
    "print('The R^2 of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('The R^2 of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1249,
     "status": "ok",
     "timestamp": 1607008847609,
     "user": {
      "displayName": "한국외대Bernardo Nugroho Yahya",
      "photoUrl": "",
      "userId": "10912533138347605083"
     },
     "user_tz": -540
    },
    "id": "6eeDkyM77pBN",
    "outputId": "44a7bb73-8abe-449d-bf84-4aef25371d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 of SVM classifier on training set: 0.30\n",
      "The R^2 of SVM classifier on test set: 0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1) # rbf : radicial basis function\n",
    "svm.fit(X_train, y_train)\n",
    "print('The R^2 of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('The R^2 of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))\n",
    "# not that good result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR / Lasso / EL_P : good(representative for data) - nonparamaetric\n",
    "# RFR : overfitting - false result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lqL5Wte7pBN"
   },
   "source": [
    "# Summary\n",
    "\n",
    "This section presents briefly about some relevant algorithms in the Regression such as Linear Regression, Lasso Regression, Ridge Regression, ElasticNet, Random Forest Regressor, and Support Vector Regressor.\n",
    "While some algorithms are non-parametric, the parametric-based algorithms such as ElasticNet and SVR requires further experiments to tune the proper parameters to find the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIPwEcQY7pBN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[Week_12_02]_Other_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
